{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cc03858",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import gymnasium as gym\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import display, clear_output\n",
    "from collections import deque\n",
    "from tqdm import tqdm\n",
    "\n",
    "from walker import PPO, Normalize\n",
    "\n",
    "RED = \"\\033[31m\"\n",
    "GREEN = \"\\033[32m\"\n",
    "YELLOW = \"\\033[33m\"\n",
    "BLUE = \"\\033[34m\"\n",
    "MAGENTA = \"\\033[35m\"\n",
    "CYAN = \"\\033[36m\"\n",
    "RESET = \"\\033[0m\"\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "57aee2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize environment\n",
    "env = gym.make('Walker2d-v4', render_mode='rgb_array')\n",
    "\n",
    "log_dir = \"../runs/20240712_02-38-11/\"\n",
    "\n",
    "# Number of state and action\n",
    "N_S = env.observation_space.shape[0]\n",
    "N_A = env.action_space.shape[0]\n",
    "\n",
    "# Initialize PPO model\n",
    "ppo = PPO(N_S, N_A, log_dir)\n",
    "normalize = Normalize(N_S, log_dir)\n",
    "\n",
    "# Load the saved model\n",
    "ppo.actor_net.load_model()\n",
    "ppo.actor_net.eval()\n",
    "normalize.load_params()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bce1dd12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "initial state:  [ 0.89948147 -0.30370082  0.19691223  0.17621902 -2.49970686  0.15205039\n",
      "  0.07187048 -2.39904975 -0.31266222  0.52422122  0.0749803   0.13616518\n",
      "  0.10759177 -0.00303725  0.14393825  0.10335399 -0.00578812]\n",
      "episode:  0 \tscore:  253.7049103505284\n",
      "initial state:  [ 0.87996205 -0.31598652  0.13826823  0.16889033 -2.57546659  0.13656154\n",
      "  0.06110285 -2.44353327 -0.33006872  0.53257142  0.06733975  0.13801706\n",
      "  0.1135697  -0.00332282  0.14558178  0.1023115  -0.00410514]\n",
      "episode:  1 \tscore:  231.4604113912506\n",
      "initial state:  [ 8.90390024e-01 -3.57219008e-01  1.78728694e-01  1.90584569e-01\n",
      " -2.58058771e+00  1.39021913e-01  7.29734214e-02 -2.48603667e+00\n",
      " -3.62913306e-01  5.46710443e-01  5.04165306e-02  1.32331474e-01\n",
      "  1.12832710e-01 -2.48476930e-03  1.41043340e-01  9.87518884e-02\n",
      " -6.58205488e-03]\n",
      "episode:  2 \tscore:  320.59776397955517\n",
      "initial state:  [ 9.56710980e-01 -3.88966792e-01  1.49134141e-01  1.53156308e-01\n",
      " -2.61293814e+00  1.29988455e-01  4.58987505e-02 -2.54581835e+00\n",
      " -3.88166161e-01  5.49574988e-01  4.44356787e-02  1.32193698e-01\n",
      "  1.05014319e-01 -1.29725704e-03  1.37004809e-01  9.75663844e-02\n",
      " -5.86367157e-03]\n",
      "episode:  3 \tscore:  288.46822914602313\n",
      "initial state:  [ 8.95892830e-01 -3.87721193e-01  1.23188091e-01  1.35875377e-01\n",
      " -2.62020211e+00  1.40684394e-01  6.83436128e-02 -2.59503047e+00\n",
      " -4.03849093e-01  5.57557224e-01  3.25517213e-02  1.28507852e-01\n",
      "  1.05374530e-01  2.32769356e-03  1.32188568e-01  9.61383743e-02\n",
      " -7.67816462e-03]\n",
      "episode:  4 \tscore:  430.119747747346\n",
      "initial state:  [ 9.21831347e-01 -4.08828956e-01  1.37060150e-01  1.51332232e-01\n",
      " -2.72563853e+00  1.64744283e-01  7.95471464e-02 -2.70325311e+00\n",
      " -4.19770989e-01  5.39085458e-01  2.03434658e-02  1.20656429e-01\n",
      "  9.53803057e-02  4.90506325e-04  1.24779709e-01  9.09193817e-02\n",
      " -1.02025136e-02]\n",
      "episode:  5 \tscore:  35.227401444427116\n",
      "initial state:  [ 0.96552647 -0.38151561  0.15064374  0.15786807 -2.6701613   0.10839543\n",
      "  0.06857912 -2.63705032 -0.40340296  0.52964023  0.03377648  0.12659691\n",
      "  0.09626225  0.00276358  0.13048914  0.09225447 -0.01092895]\n",
      "episode:  6 \tscore:  -7.215862549515019\n",
      "initial state:  [ 0.96139748 -0.38570597  0.15855106  0.15404386 -2.62992697  0.10927674\n",
      "  0.07095634 -2.59287458 -0.37687225  0.52144029  0.04149501  0.12901282\n",
      "  0.10492695  0.00269324  0.13103745  0.10446362 -0.01075807]\n",
      "episode:  7 \tscore:  265.0056191400153\n",
      "initial state:  [ 9.35041013e-01 -4.12341780e-01  1.47896068e-01  1.27039424e-01\n",
      " -2.60726145e+00  1.43022872e-01  1.02397353e-01 -2.63007454e+00\n",
      " -3.96509926e-01  5.29655437e-01  3.10523150e-02  1.23087904e-01\n",
      "  1.05463690e-01 -7.18729099e-04  1.27797469e-01  1.00826025e-01\n",
      " -1.37219331e-02]\n",
      "episode:  8 \tscore:  315.8011501465542\n",
      "initial state:  [ 9.78524283e-01 -3.94829666e-01  1.52422083e-01  1.70438421e-01\n",
      " -2.61314711e+00  1.41189442e-01  3.47547151e-02 -2.68078317e+00\n",
      " -4.14189894e-01  5.18894484e-01  2.03425316e-02  1.20515077e-01\n",
      "  9.86562602e-02  3.44193254e-04  1.23297220e-01  9.95098028e-02\n",
      " -1.43886462e-02]\n",
      "episode:  9 \tscore:  240.23951275346988\n"
     ]
    }
   ],
   "source": [
    "# Test the model\n",
    "state, _ = env.reset()\n",
    "state = normalize(state)\n",
    "\n",
    "test_total_reward = 0\n",
    "test_episodes = 10  # Number of episodes to test\n",
    "for episode_id in range(test_episodes):\n",
    "    state, _ = env.reset()\n",
    "    state = normalize(state)\n",
    "    # state = np.zeros(17)\n",
    "    print('initial state: ', state)\n",
    "    score = 0\n",
    "    for _ in range(1000):\n",
    "        action = ppo.actor_net.choose_action(state)\n",
    "        # print(f\"{YELLOW}walker velocity: {RESET}\", state[8])\n",
    "        state, reward, done, _, _ = env.step(action)\n",
    "        state = normalize(state)\n",
    "        score += reward\n",
    "\n",
    "        if done:\n",
    "            env.reset()\n",
    "            break\n",
    "    \n",
    "    print(\"episode: \", episode_id, \"\\tscore: \", score)\n",
    "env.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "867cb890",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67e81346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
